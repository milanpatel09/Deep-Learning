{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606cb836-d735-4f08-a6aa-02a46c757d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# Set to print in reasonable form\n",
    "np.set_printoptions(precision=3, floatmode=\"fixed\")\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab84bd5d-08cf-457a-893f-c539d316b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution in PyTorch\n",
    "def conv_pytorch(image, conv_weights, stride=1, pad =1):\n",
    "  # Convert image and kernel to tensors\n",
    "  image_tensor = torch.from_numpy(image) # (batchSize, channelsIn, imageHeightIn, =imageWidthIn)\n",
    "  conv_weights_tensor = torch.from_numpy(conv_weights) # (channelsOut, channelsIn, kernelHeight, kernelWidth)\n",
    "  # Do the convolution\n",
    "  output_tensor = torch.nn.functional.conv2d(image_tensor, conv_weights_tensor, stride=stride, padding=pad)\n",
    "  # Convert back from PyTorch and return\n",
    "  return(output_tensor.numpy()) # (batchSize channelsOut imageHeightOut imageHeightIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd5bdac6-d66b-4813-bf2a-09132e499fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_1(image, weights, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + imageHeightIn - kernelHeight).astype(int)\n",
    "    imageWidthOut = np.floor(1 + imageWidthIn - kernelWidth).astype(int)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    # !!!!!! NOTE THERE IS A SUBTLETY HERE !!!!!!!!\n",
    "    # I have padded the image with zeros above, so it is surrouned by a \"ring\" of zeros\n",
    "    # That means that the image indexes are all off by one\n",
    "    # This actually makes your code simpler\n",
    "\n",
    "    \n",
    "    for b in range(batchSize):\n",
    "        for c_out in range(channelsOut):\n",
    "            for c_in in range(channelsIn):\n",
    "                for c_y in range(imageHeightOut):\n",
    "                    for c_x in range(imageWidthOut):\n",
    "                        for k_y in range(kernelHeight):\n",
    "                            for k_x in range(kernelWidth):\n",
    "                                y = c_y + k_y\n",
    "                                x = c_x + k_x\n",
    "            # TODO -- Retrieve the image pixel and the weight from the convolution\n",
    "            # Only one image in batch, one input channel and one output channel, so these indices should all be zero\n",
    "                                this_pixel_value = image[b, c_in, y, x]\n",
    "                                this_weight = weights[c_out, c_in, k_y, k_x]\n",
    "                                out[b, c_out, c_y, c_x] += this_pixel_value * this_weight\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d38a76dc-c0f5-4fd3-8e44-07c5ab22d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n",
      "   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n",
      "   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n",
      "   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\n",
      "Your results\n",
      "[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n",
      "   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n",
      "   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n",
      "   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 1\n",
    "kernel_size = 3\n",
    "channels_out = 1\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_1(input_image, conv_weights)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73c42554-df5b-4a0b-97c3-d045da5fa0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_2(image, weights, stride=1, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    for c_y in range(imageHeightOut):\n",
    "      for c_x in range(imageWidthOut):\n",
    "        for c_kernel_y in range(kernelHeight):\n",
    "          for c_kernel_x in range(kernelWidth):\n",
    "              y = c_y * stride + c_kernel_y\n",
    "              x = c_x * stride + c_kernel_x\n",
    "            # TODO -- Retrieve the image pixel and the weight from the convolution\n",
    "            # Only one image in batch, one input channel and one output channel, so these indices should all be zero\n",
    "            # Replace the two lines below\n",
    "              this_pixel_value = image[0, 0, y, x]  \n",
    "              this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n",
    "\n",
    "\n",
    "            # Multiply these together and add to the output at this position\n",
    "              out[0, 0, c_y, c_x] += this_pixel_value * this_weight\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab6b4268-346d-4632-b9af-3304691bd64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n",
      "   [-0.055  1.145 -5.388 -3.910  0.097]\n",
      "   [-0.186  0.660  1.630  2.275  4.874]\n",
      "   [ 2.386 -0.225  3.288 -4.239 -1.403]\n",
      "   [ 0.825  1.710 -3.246  3.246  1.709]\n",
      "   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\n",
      "Your results\n",
      "[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n",
      "   [-0.055  1.145 -5.388 -3.910  0.097]\n",
      "   [-0.186  0.660  1.630  2.275  4.874]\n",
      "   [ 2.386 -0.225  3.288 -4.239 -1.403]\n",
      "   [ 0.825  1.710 -3.246  3.246  1.709]\n",
      "   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 12\n",
    "image_width = 10\n",
    "channels_in = 1\n",
    "kernel_size = 3\n",
    "channels_out = 1\n",
    "stride = 2\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_2(input_image, conv_weights, stride, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31563b71-28d9-4267-a970-a26f07d9d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_3(image, weights, stride=1, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    for c_y in range(imageHeightOut):\n",
    "        for c_x in range(imageWidthOut):\n",
    "            for c_channel_out in range(channelsOut):\n",
    "                for c_channel_in in range(channelsIn):\n",
    "                    for k_y in range(kernelHeight):\n",
    "                        for k_x in range(kernelWidth):\n",
    "                            # Calculate the actual pixel location based on stride\n",
    "                            y = c_y * stride + k_y\n",
    "                            x = c_x * stride + k_x\n",
    "\n",
    "                            # Retrieve the image pixel and the weight from the convolution\n",
    "                            this_pixel_value = image[0, c_channel_in, y, x]  # Only one image in batch\n",
    "                            this_weight = weights[c_channel_out, c_channel_in, k_y, k_x]\n",
    "\n",
    "                            # Multiply these together and add to the output at this position\n",
    "                            out[0, c_channel_out, c_y, c_x] += this_pixel_value * this_weight\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f27bd0cf-cbd6-4821-a49b-4f13bd99c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n",
      "   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n",
      "   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n",
      "   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n",
      "\n",
      "  [[  4.150   5.372   1.699   0.500   0.589   4.361]\n",
      "   [ -4.123   5.136   4.677  -3.895  -4.990   2.546]\n",
      "   [  3.991   5.768  -2.315   8.473   1.752   2.766]\n",
      "   [  1.529   0.318  11.518  -5.444  -2.293   1.270]]]]\n",
      "Your results\n",
      "[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n",
      "   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n",
      "   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n",
      "   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n",
      "\n",
      "  [[  4.150   5.372   1.699   0.500   0.589   4.361]\n",
      "   [ -4.123   5.136   4.677  -3.895  -4.990   2.546]\n",
      "   [  3.991   5.768  -2.315   8.473   1.752   2.766]\n",
      "   [  1.529   0.318  11.518  -5.444  -2.293   1.270]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 5\n",
    "kernel_size = 3\n",
    "channels_out = 2\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_3(input_image, conv_weights, stride=1, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f0791f2-d89b-495d-bb9a-9717fb30fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_4(image, weights, stride=1, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    for c_batch in range(batchSize):\n",
    "        for c_y in range(imageHeightOut):\n",
    "            for c_x in range(imageWidthOut):\n",
    "                for c_channel_out in range(channelsOut):\n",
    "                    for c_channel_in in range(channelsIn):\n",
    "                        for c_kernel_y in range(kernelHeight):\n",
    "                            for c_kernel_x in range(kernelWidth):\n",
    "                                # Calculate the actual pixel location based on stride\n",
    "                                y = c_y * stride + c_kernel_y\n",
    "                                x = c_x * stride + c_kernel_x\n",
    "\n",
    "                                # Retrieve the image pixel and the weight from the convolution\n",
    "                                this_pixel_value = image[c_batch, c_channel_in, y, x]  # Image pixel value\n",
    "                                this_weight = weights[c_channel_out, c_channel_in, c_kernel_y, c_kernel_x]  # Kernel weight\n",
    "\n",
    "                                # Multiply these together and add to the output at this position\n",
    "                                out[c_batch, c_channel_out, c_y, c_x] += this_pixel_value * this_weight\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8da9b359-bceb-4b8b-8fbf-70be63aaa5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[ -3.633  -1.644   0.169  -1.167  -3.865   6.045]\n",
      "   [ -9.004   7.303   4.414   0.361  -6.739   3.939]\n",
      "   [ -1.391  13.502   3.807  -9.379   3.991   5.442]\n",
      "   [  2.805   6.874  -9.287  -4.468  -1.501   4.607]]\n",
      "\n",
      "  [[  1.940  -1.410   2.397  -0.235  -0.394  -1.483]\n",
      "   [  5.049  -3.335  -7.596  -1.586   3.049  -1.857]\n",
      "   [  3.514   0.475  -1.952  -1.291  -0.589  -0.948]\n",
      "   [  6.524  -0.020  -3.298  -1.248   3.249  -2.680]]]\n",
      "\n",
      "\n",
      " [[[  4.154  -4.764  11.635   0.506  -4.012  -2.081]\n",
      "   [ -1.125  -0.677  16.749  -7.030  -5.978  -2.629]\n",
      "   [  0.778  -3.984 -10.284   1.575  -8.888   1.163]\n",
      "   [  0.556  -2.290   1.407  -3.088   2.227  -5.403]]\n",
      "\n",
      "  [[  1.048   4.322  -0.901  -5.820   3.998   2.281]\n",
      "   [ -1.313   8.409  -0.100  14.625   1.223  -3.572]\n",
      "   [  1.411   1.617  -4.078  -8.107   3.705   0.229]\n",
      "   [ -3.540  -5.292  -5.619  -4.039  -4.048  -3.446]]]]\n",
      "Your results\n",
      "[[[[ -3.633  -1.644   0.169  -1.167  -3.865   6.045]\n",
      "   [ -9.004   7.303   4.414   0.361  -6.739   3.939]\n",
      "   [ -1.391  13.502   3.807  -9.379   3.991   5.442]\n",
      "   [  2.805   6.874  -9.287  -4.468  -1.501   4.607]]\n",
      "\n",
      "  [[  1.940  -1.410   2.397  -0.235  -0.394  -1.483]\n",
      "   [  5.049  -3.335  -7.596  -1.586   3.049  -1.857]\n",
      "   [  3.514   0.475  -1.952  -1.291  -0.589  -0.948]\n",
      "   [  6.524  -0.020  -3.298  -1.248   3.249  -2.680]]]\n",
      "\n",
      "\n",
      " [[[  4.154  -4.764  11.635   0.506  -4.012  -2.081]\n",
      "   [ -1.125  -0.677  16.749  -7.030  -5.978  -2.629]\n",
      "   [  0.778  -3.984 -10.284   1.575  -8.888   1.163]\n",
      "   [  0.556  -2.290   1.407  -3.088   2.227  -5.403]]\n",
      "\n",
      "  [[  1.048   4.322  -0.901  -5.820   3.998   2.281]\n",
      "   [ -1.313   8.409  -0.100  14.625   1.223  -3.572]\n",
      "   [  1.411   1.617  -4.078  -8.107   3.705   0.229]\n",
      "   [ -3.540  -5.292  -5.619  -4.039  -4.048  -3.446]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 2\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 5\n",
    "kernel_size = 3\n",
    "channels_out = 2\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_4(input_image, conv_weights, stride=1, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
